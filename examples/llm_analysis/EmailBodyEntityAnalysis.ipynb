{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89e4f9",
   "metadata": {},
   "source": [
    "# Email body content analysis \n",
    "\n",
    "*For the context:* Current analysis in bigbang focus on headers. There are many analysis on the headers in the emails for the people and orgnization involved in the discussions. There are a few content analysis focusing on the keywords first occurence searching and/or most used words per user.\n",
    "\n",
    "This notebook analyze the email body contents with Huggingface Named Entity Recognition(NER) models that are able to systematically label the entities and their types(currently supports PER, ORG, LOC, and MISC) in the email bodies. This can potentially help the researchers understand more on the email conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aadfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from bigbang.archive import Archive\n",
    "from bigbang.archive import load as load_archive\n",
    "import pandas as pd\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5230a",
   "metadata": {},
   "source": [
    "First, use the script ```bin/collect_mail.py``` to collect web archives. Details can be seen in https://bigbang-py.readthedocs.io/en/latest/data-sources.html#id1 .\n",
    "\n",
    "<!-- Here, we use an example of the [scipy-dev](https://mail.python.org/pipermail/scipy-dev/) mailing list page.\n",
    "\n",
    "Scipy-dev mailing list contains 149,718 emails From June 2001 - September 2021. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d286f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailing_list = \"scipy-dev\"\n",
    "archive_path = \"../../archives/{}/\".format(mailing_list)\n",
    "archive = Archive(archive_path, mbox=True)\n",
    "# archive data in pandas dataframe format\n",
    "archive_data = archive.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a767ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date</th>\n",
       "      <th>In-Reply-To</th>\n",
       "      <th>References</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Message-ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net&gt;</th>\n",
       "      <td>travis at vaught.net (Travis N. Vaught)</td>\n",
       "      <td>[SciPy-dev] SciPy Developer mailing list now o...</td>\n",
       "      <td>2001-06-11 02:10:51+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The link:\\n\\nhttp://scipy.net/mailman/listinfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;Pine.LNX.4.33.0107231957590.15960-100000@oliphant.ee.byu.edu&gt;</th>\n",
       "      <td>oliphant at ee.byu.edu (Travis Oliphant)</td>\n",
       "      <td>[SciPy-dev] RPMs and source distribution</td>\n",
       "      <td>2001-07-24 02:01:00+00:00</td>\n",
       "      <td>&lt;02f001c111bf$2e78a9d0$777ba8c0@190xb01&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>I've been playing for hours and finally have i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        From   \n",
       "Message-ID                                                                                     \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>     travis at vaught.net (Travis N. Vaught)  \\\n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph...  oliphant at ee.byu.edu (Travis Oliphant)   \n",
       "\n",
       "                                                                                              Subject   \n",
       "Message-ID                                                                                              \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>    [SciPy-dev] SciPy Developer mailing list now o...  \\\n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph...           [SciPy-dev] RPMs and source distribution   \n",
       "\n",
       "                                                                        Date   \n",
       "Message-ID                                                                     \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>   2001-06-11 02:10:51+00:00  \\\n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph... 2001-07-24 02:01:00+00:00   \n",
       "\n",
       "                                                                                 In-Reply-To   \n",
       "Message-ID                                                                                     \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>                                        None  \\\n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph...  <02f001c111bf$2e78a9d0$777ba8c0@190xb01>   \n",
       "\n",
       "                                                   References   \n",
       "Message-ID                                                      \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>         None  \\\n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph...       None   \n",
       "\n",
       "                                                                                                 Body  \n",
       "Message-ID                                                                                             \n",
       "<NEBBIECAMLMAAKHEGPCGKEBHCLAA.travis@vaught.net>    The link:\\n\\nhttp://scipy.net/mailman/listinfo...  \n",
       "<Pine.LNX.4.33.0107231957590.15960-100000@oliph...  I've been playing for hours and finally have i...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data\n",
    "print(len(archive_data))\n",
    "archive_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3316be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've been playing for hours and finally have it so that\\n\\npython setup.py sdist\\npython setup.by bdist_rpm\\n\\nwork as expected.\\n\\nI have distributions and RPM's that I need to put somewhere.\\n\\nThanks,\\n\\n-Travis\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of one email body\n",
    "list(archive_data[\"Body\"].iloc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbc5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment line below to install transformers with pytorch\n",
    "# inside your current python environment\n",
    "\n",
    "# !pip install transformers[torch]\n",
    "# !pip install contractions\n",
    "# !pip install email_reply_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542b1fa",
   "metadata": {},
   "source": [
    "In pre-processing, we want to \n",
    "- remove the punctuations\n",
    "- remove links \n",
    "- expand contractions \n",
    "- remove digits\n",
    "- tokenize the words\n",
    "- [Optional] Lowercase the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7175c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions for analyzing\n",
    "from bigbang.analysis.entity_recognition import EntityRecognizer, SpanVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac1bba",
   "metadata": {},
   "source": [
    "The list of models can be found in: https://huggingface.co/ . You can also train your own model and upload to huggingface.\n",
    "\n",
    "Examples for possible model names include:\n",
    "['dslim/bert-base-NER', 'dslim/bert-base-NER-cased', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbd42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the model and apply inference in the back-end of the bigbang package\n",
    "# you can pass the model name of your interest to the function\n",
    "model_name = \"EffyLi/bert-base-NER-finetuned-ner-cerec\"\n",
    "\n",
    "recognizer = EntityRecognizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd9a18c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text body before pre-processing--------------------:\n",
      "\n",
      "All,\n",
      "\n",
      "As I mentioned in my previous message, I've been trying to patch\n",
      "Fortran compilation to support f2c. Unfortunately, after some\n",
      "work on patching both build_flib.py and the fc f2c script, I ran\n",
      "into several problems.\n",
      "\n",
      "1. fc puts the files into the current directory.\n",
      "2. The build process runs into problems with the space in the\n",
      "platform name which contains \"Power Macintosh\". In particular,\n",
      "ar has problems with the space.\n",
      "\n",
      "I think, I'll wait until gcc 3.0 on OS X. That will have g77 support.\n",
      "\n",
      "Cheers,\n",
      "\n",
      "Tim Lahey\n",
      "Text body after pre-processing--------------------:\n",
      "\n",
      "All,  As I mentioned in my previous message, I have been trying to patch Fortran compilation to support fc. Unfortunately, after some work on patching both build_flib.py and the fc fc script, I ran into several problems.  . fc puts the files into the current directory. . The build process runs into problems with the space in the platform name which contains \"Power Macintosh\". In particular, ar has problems with the space.  I think, I will wait until gcc . on OS X. That will have g support.  Cheers,  Tim Lahey\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# hyperparams\n",
    "# taking one row as an example\n",
    "index = 6\n",
    "lowercase = False\n",
    "\n",
    "body = list(archive_data[\"Body\"].iloc[[index]])[0]\n",
    "print(\"Text body before pre-processing--------------------:\\n\")\n",
    "print(body)\n",
    "body = recognizer.pre_processing(body, lowercase=lowercase)\n",
    "print(\"Text body after pre-processing--------------------:\\n\")\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68358157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-PER', 'word': 'I'}\n",
      "{'entity': 'B-PER', 'word': 'I'}\n",
      "{'entity': 'B-ORG', 'word': 'Fort'}\n",
      "{'entity': 'I-PER', 'word': '##ran'}\n",
      "{'entity': 'B-PER', 'word': 'build'}\n",
      "{'entity': 'I-PER', 'word': 'fl'}\n",
      "{'entity': 'I-PER', 'word': '##ib'}\n",
      "{'entity': 'I-PER', 'word': 'p'}\n",
      "{'entity': 'B-PER', 'word': 'I'}\n",
      "{'entity': 'I-PER', 'word': 'f'}\n",
      "{'entity': 'I-PER', 'word': '##c'}\n",
      "{'entity': 'B-MISC', 'word': 'Power'}\n",
      "{'entity': 'I-MISC', 'word': 'Macintosh'}\n",
      "{'entity': 'B-PER', 'word': 'a'}\n",
      "{'entity': 'B-PER', 'word': 'I'}\n",
      "{'entity': 'B-PER', 'word': 'Tim'}\n",
      "{'entity': 'I-PER', 'word': 'La'}\n",
      "{'entity': 'I-PER', 'word': '##hey'}\n"
     ]
    }
   ],
   "source": [
    "tokens = recognizer.tokenizer.tokenize(body)\n",
    "labels = recognizer.recognize(body)\n",
    "entities = recognizer.get_entities(labels)\n",
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31837549",
   "metadata": {},
   "source": [
    "*[Optional]* We can also visualize the results with spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8cf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment following line to install spacy package\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "432cf36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All , As \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " mentioned in my previous message , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " have been trying to patch \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fortran\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " compilation to support fc . Unfortunately , after some work on patching both \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    build\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " _ \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    flib\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    py\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " and the fc fc script , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " ran into several problems . . \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " puts the files into the current directory . . The build process runs into problems with the space in the platform name which contains &quot; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Power Macintosh\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " &quot; . In particular , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " has problems with the space . I think , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " will wait until gcc . on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ALLCAPS</span>\n",
       "</mark>\n",
       " X . That will have g support . Cheers , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tim Lahey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span, Doc\n",
    "\n",
    "# # defining a score threshold on the recognized entities. only entity has scored above the threshold will show\n",
    "# threashold = 0.0\n",
    "find_all_caps = True\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vocab = nlp.tokenizer.vocab\n",
    "\n",
    "visualizer = SpanVisualizer()\n",
    "merged_tokens = visualizer.merge_tokens(tokens)\n",
    "doc = Doc(vocab=vocab, words=merged_tokens)\n",
    "doc = visualizer.get_doc_for_visualization(tokens, labels, body, doc, find_all_caps)\n",
    "\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23c2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity type:  PER\n",
      "\t- I\n",
      "\t- build\n",
      "\t- flib\n",
      "\t- py\n",
      "\t- fc\n",
      "\t- ar\n",
      "\t- Tim Lahey\n",
      "entity type:  ORG\n",
      "\t- Fortran\n",
      "entity type:  MISC\n",
      "\t- Power Macintosh\n",
      "entity type:  ALLCAPS\n",
      "\t- OS\n"
     ]
    }
   ],
   "source": [
    "visualizer.get_list_per_type()\n",
    "entity_type_list = visualizer.entity_type\n",
    "for typ, ent_list in entity_type_list.items():\n",
    "    print(\"entity type: \", typ)\n",
    "    for ent in ent_list:\n",
    "        print(\"\\t-\", ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78f5a1",
   "metadata": {},
   "source": [
    "## Processing the whole mailing list\n",
    "\n",
    "In the end, we show one example of how to pass a list of emails and return a list of entities with types. We save them in a csv file for futher processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c99e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \"i\",\n",
    "    \"you\",\n",
    "    \"me\",\n",
    "    \"my\",\n",
    "    \"mine\",\n",
    "    \"myself\",\n",
    "    \"your\",\n",
    "    \"yours\",\n",
    "    \"yourself\",\n",
    "    \"we\",\n",
    "    \"us\",\n",
    "    \"our\",\n",
    "    \"ours\",\n",
    "    \"ourselves\",\n",
    "    \"yourselves\",\n",
    "    \"he\",\n",
    "    \"him\",\n",
    "    \"himself\",\n",
    "    \"his\",\n",
    "    \"she\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"herself\",\n",
    "    \"it\",\n",
    "    \"its\",\n",
    "    \"itself\",\n",
    "    \"they\",\n",
    "    \"them\",\n",
    "    \"their\",\n",
    "    \"theirs\",\n",
    "    \"themself\",\n",
    "    \"themselves\",\n",
    "    \"this\",\n",
    "    \"that\",\n",
    "    \"something\",\n",
    "    \"these\",\n",
    "    \"those\",\n",
    "    \"someone\",\n",
    "    \"somebody\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"whose\",\n",
    "    \"which\",\n",
    "    \"what\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168ef5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 50 emails in total\n",
      "0 emails processed, 50 emails left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities saved!\n",
      "entity type:  PER\n",
      "\t- you\n",
      "\t- scipy - dev\n",
      "\t- scipy . net\n",
      "\t- I\n",
      "\t- I\n",
      "\t- py\n",
      "\t- I\n",
      "\t- Travis\n",
      "\t- I\n",
      "\t- I\n",
      "\t- SciPy\n",
      "\t- my\n",
      "\t- flib\n",
      "\t- py\n",
      "\t- Cephes\n",
      "\t- Tim Lahey\n",
      "\t- I\n",
      "\t- build\n",
      "\t- flib\n",
      "\t- py\n",
      "\t- fc\n",
      "\t- ar\n",
      "\t- Tim Lahey\n",
      "\t- I\n",
      "\t- us\n",
      "\t- de Boor\n",
      "\t- Tim Lahey\n",
      "\t- Tim\n",
      "\t- I\n",
      "\t- Travis Oliphant\n",
      "\t- he\n",
      "\t- you\n",
      "\t- Travis O .\n",
      "\t- I\n",
      "\t- your\n",
      "\t- I\n",
      "\t- splines\n",
      "\t- I\n",
      "\t- Carl de Boor\n",
      "\t- Joe\n",
      "\t- You\n",
      "\t- you\n",
      "\t- me\n",
      "\t- your\n",
      "\t- We\n",
      "\t- your member\n",
      "\t- I\n",
      "\t- everyone\n",
      "\t- eric\n",
      "\t- I\n",
      "\t- me\n",
      "\t- Joe rossini\n",
      "\t- you\n",
      "\t- washington . edu\n",
      "\t- A . J . Rossini\n",
      "\t- I\n",
      "\t- anyone\n",
      "\t- us\n",
      "\t- you\n",
      "\t- Travis Vaught\n",
      "\t- I\n",
      "\t- rossini\n",
      "\t- A . J . Rossini\n",
      "\t- I\n",
      "\t- me\n",
      "\t- you\n",
      "\t- JMR\n",
      "\t- I\n",
      "\t- Eric\n",
      "\t- he\n",
      "\t- Numpy\n",
      "\t- I\n",
      "\t- Rob\n",
      "\t- ps\n",
      "\t- my Fortran\n",
      "\t- I\n",
      "\t- linalg\n",
      "\t- Travis O .\n",
      "\t- we\n",
      "\t- you\n",
      "\t- lapack\n",
      "\t- pyf\n",
      "\t- I\n",
      "\t- I\n",
      "\t- I\n",
      "\t- I\n",
      "\t- cygwin\n",
      "\t- fpy\n",
      "\t- me\n",
      "\t- Pearu\n",
      "\t- I\n",
      "\t- Pearu\n",
      "\t- I\n",
      "\t- me\n",
      "\t- Jochen\n",
      "\t- Jason\n",
      "\t- I\n",
      "\t- me\n",
      "\t- Cygwin\n",
      "\t- Jason\n",
      "\t- Travis\n",
      "\t- cygwin\n",
      "\t- Pearu\n",
      "\t- Jochen\n",
      "\t- you\n",
      "\t- my\n",
      "\t- I\n",
      "\t- libpython\n",
      "\t- dll\n",
      "\t- You\n",
      "\t- distutils\n",
      "\t- sig\n",
      "\t- python . org\n",
      "\t- Jason\n",
      "\t- I\n",
      "\t- my\n",
      "\t- Pearu\n",
      "\t- I\n",
      "\t- you\n",
      "\t- ravel\n",
      "\t- Matlab\n",
      "\t- Zope\n",
      "\t- you\n",
      "\t- I\n",
      "\t- I\n",
      "\t- William\n",
      "\t- everyone\n",
      "\t- My\n",
      "\t- plt\n",
      "\t- You\n",
      "\t- I\n",
      "\t- PythonCard\n",
      "\t- PyCrust\n",
      "\t- she\n",
      "\t- I\n",
      "\t- they\n",
      "\t- PowerPoint\n",
      "\t- my\n",
      "\t- Kevin Altis altis\n",
      "\t- semi\n",
      "\t- retired . com\n",
      "\t- I\n",
      "\t- Jochen\n",
      "\t- Einigkeit\n",
      "\t- SunOS\n",
      "\t- I\n",
      "\t- Jochen\n",
      "\t- you\n",
      "\t- your\n",
      "\t- pyCrust\n",
      "\t- wxPython\n",
      "\t- gui _ thread\n",
      "\t- Python\n",
      "\t- plt\n",
      "\t- py\n",
      "\t- I\n",
      "\t- wxGTK\n",
      "\t- I\n",
      "\t- me\n",
      "\t- eric\n",
      "\t- Sun\n",
      "\t- I\n",
      "\t- you\n",
      "\t- your\n",
      "\t- me\n",
      "\t- SciPy\n",
      "\t- build\n",
      "\t- flib . py\n",
      "\t- eric\n",
      "\t- I\n",
      "\t- f\n",
      "\t- dryrun\n",
      "\t- eric\n",
      "\t- BEGIN\n",
      "\t- I\n",
      "\t- plt\n",
      "\t- you\n",
      "\t- py\n",
      "\t- my\n",
      "\t- gui\n",
      "\t- plot . py\n",
      "\t- kplot . py\n",
      "\t- Greetings , Jochen\n",
      "\t- Venable Hall\n",
      "\t- #\n",
      "\t- Kenan C\n",
      "\t- Hill\n",
      "entity type:  DIG\n",
      "\t- list\n",
      "\t- representation\n",
      "\t- Guide\n",
      "\t- Mathematics\n",
      "\t- org\n",
      "\t- THREADS\n",
      "\t- THEM Project www . members . home . net / europax\n",
      "\t- directory\n",
      "\t- _\n",
      "\t- document\n",
      "\t- jkext\n",
      "entity type:  ORG\n",
      "\t- our\n",
      "\t- they\n",
      "\t- Distutils\n",
      "\t- PyOpenGL\n",
      "\t- Fortran\n",
      "\t- SciPy\n",
      "\t- CVS\n",
      "\t- SLATEC\n",
      "\t- Netlib\n",
      "\t- SLATEC\n",
      "\t- we\n",
      "\t- SciPy\n",
      "\t- we\n",
      "\t- SciPy\n",
      "\t- they\n",
      "\t- SLATEC\n",
      "\t- spline\n",
      "\t- Springer - Verlag\n",
      "\t- we\n",
      "\t- scipy . org\n",
      "\t- scipy\n",
      "\t- .\n",
      "\t- our\n",
      "\t- edu\n",
      "\t- We\n",
      "\t- We\n",
      "\t- we\n",
      "\t- We\n",
      "\t- we\n",
      "\t- blindglobe\n",
      "\t- FORTRAN\n",
      "\t- USENET\n",
      "\t- ATLAS\n",
      "\t- FreeBSD\n",
      "\t- ATLAS\n",
      "\t- ATLAS\n",
      "\t- CYGWIN\n",
      "\t- CYGWIN\n",
      "\t- Cygwin\n",
      "\t- Modules\n",
      "\t- Distutils\n",
      "\t- NumPy\n",
      "\t- NumPy\n",
      "\t- Matlab\n",
      "\t- AppleEvents\n",
      "\t- Excel\n",
      "\t- SciPy\n",
      "\t- PythonCard\n",
      "\t- University of North Carolina\n",
      "\t- Department of Chemistry\n",
      "\t- und Recht\n",
      "\t- Freiheit\n",
      "\t- Fortran\n",
      "\t- PlotCanvas\n",
      "\t- scipy\n",
      "\t- University of North Carolina\n",
      "\t- Department of Chemistry\n",
      "\t- NC\n",
      "\t- BCCDE\n",
      "entity type:  MISC\n",
      "\t- Mac OS X\n",
      "\t- Power Macintosh\n",
      "\t- Python\n",
      "\t- Windows\n",
      "\t- Debian\n",
      "\t- C\n",
      "\t- Windows\n",
      "\t- Python\n",
      "\t- Cygwin Python\n",
      "\t- Calcusyn\n",
      "\t- Python\n",
      "entity type:  ALLCAPS\n",
      "\t- OS\n",
      "\t- GIST\n",
      "\t- OS\n",
      "\t- OS\n",
      "\t- BSPEV\n",
      "\t- BSPVD\n",
      "\t- BSPPP\n",
      "\t- BINTK\n",
      "\t- BINT\n",
      "\t- BSQAD\n",
      "\t- PPQAD\n",
      "\t- BFQAD\n",
      "\t- PFQAD\n",
      "\t- BVALU\n",
      "\t- PPVAL\n",
      "\t- INTRV\n",
      "\t- BSPDR\n",
      "\t- BSPVN\n",
      "\t- FEM\n",
      "\t- RH\n",
      "\t- AIX\n",
      "\t- LAPACK\n",
      "\t- SAVE\n",
      "\t- LAPACK\n",
      "\t- LAPACK\n",
      "\t- GCC\n",
      "\t- RCS\n",
      "\t- NC\n",
      "\t- USA\n",
      "\t- EXPORT\n",
      "\t- EXPORT\n",
      "\t- BCCDE\n",
      "\t- URL\n",
      "\t- EXPORT\n",
      "\t- IMPORT\n",
      "\t- PM\n",
      "\t- PDF\n",
      "\t- COM\n",
      "\t- PGP\n",
      "\t- BEGIN\n",
      "\t- SHA\n",
      "\t- BCCDE\n",
      "\t- END\n",
      "\t- BEGIN\n",
      "\t- PGP\n",
      "\t- SIGNED\n",
      "\t- SHA\n",
      "\t- RCS\n",
      "\t- BCCDE\n",
      "\t- END\n",
      "\t- SUN\n",
      "\t- GTK\n",
      "\t- DISPLAY\n",
      "\t- SIGNED\n",
      "\t- RCS\n",
      "\t- PNG\n",
      "\t- BMP\n",
      "\t- JPEG\n",
      "\t- PCX\n",
      "\t- TIFF\n",
      "\t- BCCDE\n",
      "\t- RCS\n",
      "\t- USA\n",
      "entity type:  LOC\n",
      "\t- New York ,\n",
      "\t- SciPy site\n",
      "\t- SciPy\n",
      "\t- Chapel Hill , NC\n",
      "\t- USA\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# taking a list of indexes as examples\n",
    "num_data = len(archive_data)\n",
    "num_data = 50\n",
    "print(\"Process {} emails in total\".format(num_data))\n",
    "indexes = list(range(0, num_data))\n",
    "lowercase = False\n",
    "find_all_caps = True\n",
    "\n",
    "model_name = \"EffyLi/bert-base-NER-finetuned-ner-cerec\"\n",
    "# model_name = \"dslim/bert-base-NER\"\n",
    "recognizer = EntityRecognizer(model_name)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vocab = nlp.tokenizer.vocab\n",
    "save_file_path = \"../../archives/\"\n",
    "save_file_name = archive_path.split(\"/\")[-2] + \"-entities.csv\"\n",
    "columns_names = [\"email_id\", \"entity\", \"type\"]\n",
    "df = pd.DataFrame(columns=columns_names)\n",
    "\n",
    "email_entity_types = defaultdict(list)\n",
    "\n",
    "# print('Process emails with id: ', indexes)\n",
    "for index in indexes:\n",
    "    if index % 200 == 0:\n",
    "        print(\"{} emails processed, {} emails left.\".format(index, (num_data - index)))\n",
    "    body = list(archive_data[\"Body\"].iloc[[index]])[0]\n",
    "    body = recognizer.pre_processing(body, lowercase=lowercase)\n",
    "    #     show email bodies after pre-processing\n",
    "    #     print(body)\n",
    "\n",
    "    visualizer = SpanVisualizer()\n",
    "    # get labels from recognizer first\n",
    "    tokens = recognizer.tokenizer.tokenize(body)\n",
    "    labels = recognizer.recognize(body)\n",
    "    # merge tokens and spans in visualizer\n",
    "    merged_tokens = visualizer.merge_tokens(tokens)\n",
    "    doc = Doc(vocab=vocab, words=merged_tokens)\n",
    "    doc = visualizer.get_doc_for_visualization(tokens, labels, body, doc, find_all_caps)\n",
    "    visualizer.get_list_per_type()\n",
    "    entity_type = visualizer.entity_type\n",
    "    for k, v in entity_type.items():\n",
    "        email_entity_types[k].extend(v)\n",
    "        for v_i in v:\n",
    "            # remove pronouns\n",
    "            if v_i.lower() not in stop_words:\n",
    "                new_row = {\"email_id\": index, \"entity\": v_i, \"type\": k}\n",
    "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df.to_csv(save_file_name)\n",
    "print(\"Extracted entities saved!\")\n",
    "\n",
    "for typ, ent_list in email_entity_types.items():\n",
    "    print(\"entity type: \", typ)\n",
    "    for ent in ent_list:\n",
    "        print(\"\\t-\", ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e1de8",
   "metadata": {},
   "source": [
    "## Run the cell below only to display pre-processed mailing list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load pre-processed csv file to dataframe and display\n",
    "file_path = \"extracted_entities/3gv6-entities.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# get top 10 frequent entities for each category\n",
    "categories = list(set(recognizer.model.config.id2label.values()))\n",
    "categories = list(set([c.split(\"-\")[-1] if \"-\" in c else c for c in categories]))\n",
    "\n",
    "for c in categories:\n",
    "    if c != \"O\":\n",
    "        if c == \"PER\":\n",
    "            print(\"Top 10 occurence (pronouns excluded) for type: \", c)\n",
    "        else:\n",
    "            print(\"Top 10 occurence for type: \", c)\n",
    "        df_c = df.loc[df[\"type\"] == c]\n",
    "        display_df = (\n",
    "            df_c[\"entity\"]\n",
    "            .value_counts()\n",
    "            .rename_axis(\"entity\")\n",
    "            .reset_index(name=\"counts\")\n",
    "        )\n",
    "        display(display_df.head(10))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e1ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigbang2",
   "language": "python",
   "name": "bigbang2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
