{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This notebook takes the whole list of users and save on a file the most recurring words per each user</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bigbang.archive import load as load_archive\n",
    "from bigbang.archive import Archive\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from pandas import DataFrame as df\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import re\n",
    "\n",
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify if you want to have words stemmed (no prefixes, plurals, etc.) or literal\n",
    "stem = False\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "archives_names = [\"6lo\"]\n",
    "\n",
    "\n",
    "archive_paths = list()\n",
    "for archive_name in archives_names:\n",
    "    archive_paths.append(\"../../archives/\" + archive_name + \".csv\")\n",
    "\n",
    "\n",
    "archives_list = [load_archive(arch_path).data for arch_path in archive_paths]\n",
    "\n",
    "archives = Archive(pd.concat(archives_list))\n",
    "archives_data = archives.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing a function to count top words per user\n",
    "\n",
    "\n",
    "def count_words(texts):\n",
    "    wordcount = {}\n",
    "    for text in texts:\n",
    "        w = text.replace(\"'\", \"\")\n",
    "        k = re.sub(r\"[^\\w]\", \" \", w)\n",
    "        t = tokenize.word_tokenize(k)\n",
    "        for g in t:\n",
    "            try:\n",
    "                if stem:\n",
    "                    word = st.stem(g)\n",
    "                else:\n",
    "                    word = g\n",
    "            except:\n",
    "                print(g)\n",
    "                pass\n",
    "            if word in stopwords.words(\"english\"):\n",
    "                continue\n",
    "            if word not in wordcount:\n",
    "                wordcount[word] = [1]\n",
    "            else:\n",
    "                wordcount[word][0] += 1\n",
    "    return wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the list of users and compute the word count per each user (might take some time!)\n",
    "\n",
    "user_wordcount = defaultdict(int)\n",
    "\n",
    "users = list(archives_data[\"From\"])\n",
    "\n",
    "for user in set(users):\n",
    "    try:\n",
    "        messages = archives_data[archives_data[\"From\"] == user][\"Body\"]\n",
    "        user_wordcount[user] = count_words(messages)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported!\n"
     ]
    }
   ],
   "source": [
    "# insert the number of top words you want to export\n",
    "n_top_words = 10\n",
    "\n",
    "# edit the file name in case...\n",
    "users_topwords_f = open(\"users_topwords.csv\", \"wb\")\n",
    "users_w = csv.writer(users_topwords_f)\n",
    "\n",
    "for user, wordcount in user_wordcount.items():\n",
    "    for word, count in sorted(\n",
    "        iter(wordcount.items()), reverse=True, key=lambda k_v: (k_v[1], k_v[0])\n",
    "    )[:n_top_words]:\n",
    "        users_w.writerow([user] + [word] + [count[0]])\n",
    "users_topwords_f.close()\n",
    "print(\"File exported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
