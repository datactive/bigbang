{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This notebook takes a list of users and outputs the most recurring words per each user</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bigbang.archive import load as load_archive\n",
    "from bigbang.archive import Archive\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from pandas import DataFrame as df\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import re\n",
    "\n",
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert ONE url of mailing list\n",
    "list_name = \"ietf\"\n",
    "\n",
    "\n",
    "# specify if you want to have words stemmed (no prefixes, pluralrs, etc.) or literal\n",
    "stem = False\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "ml_names = [\"6lo\"]\n",
    "\n",
    "\n",
    "arch_paths = list()\n",
    "for ml_name in ml_names:\n",
    "    arch_paths.append(\"../../archives/\" + ml_name + \".csv\")\n",
    "\n",
    "\n",
    "archives_list = [load_archive(arch_path).data for arch_path in arch_paths]\n",
    "\n",
    "archives = Archive(pd.concat(archives_list))\n",
    "archives_data = archives.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing a function to count top words per user\n",
    "\n",
    "\n",
    "def count_words(texts):\n",
    "    wordcount = {}\n",
    "    for text in texts:\n",
    "        w = text.replace(\"'\", \"\")\n",
    "        k = re.sub(r\"[^\\w]\", \" \", w)\n",
    "        t = tokenize.word_tokenize(k)\n",
    "        for g in t:\n",
    "            try:\n",
    "                if stem:\n",
    "                    word = st.stem(g)\n",
    "                else:\n",
    "                    word = g\n",
    "            except:\n",
    "                print(g)\n",
    "                pass\n",
    "            if word in stopwords.words(\"english\"):\n",
    "                continue\n",
    "            if word not in wordcount:\n",
    "                wordcount[word] = [1]\n",
    "            else:\n",
    "                wordcount[word][0] += 1\n",
    "    return wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From\n",
      "\"Pascal Thubert (pthubert)\" <pthubert@cisco.com>                        279.0\n",
      "Samita Chakrabarti <samita.chakrabarti@ericsson.com>                    212.0\n",
      "Carsten Bormann <cabo@tzi.org>                                          187.0\n",
      "internet-drafts@ietf.org                                                136.0\n",
      "Michael Richardson <mcr+ietf@sandelman.ca>                               93.0\n",
      "Ulrich Herberg <ulrich@herberg.name>                                     91.0\n",
      "Robert Cragie <robert.cragie@gridmerge.com>                              77.0\n",
      "Alexandru Petrescu <alexandru.petrescu@gmail.com>                        72.0\n",
      "Brian Haberman <brian@innovationslab.net>                                61.0\n",
      "Gabriel Montenegro <Gabriel.Montenegro@microsoft.com>                    60.0\n",
      "Ralph Droms <rdroms.ietf@gmail.com>                                      56.0\n",
      "\"6lo issue tracker\" <trac+6lo@tools.ietf.org>                            55.0\n",
      "Kerry Lynn <kerlyn@ieee.org>                                             49.0\n",
      "Samita Chakrabarti <samitac.ietf@gmail.com>                              44.0\n",
      "Behcet Sarikaya <sarikaya2012@gmail.com>                                 35.0\n",
      "Juergen Schoenwaelder <j.schoenwaelder@jacobs-university.de>             32.0\n",
      "peter van der Stok <stokcons@xs4all.nl>                                  31.0\n",
      "James Woodyatt <jhw@nestlabs.com>                                        29.0\n",
      "\"Carles Gomez Montenegro\" <carlesgo@entel.upc.edu>                       29.0\n",
      "<teemu.savolainen@nokia.com>                                             28.0\n",
      "The IESG <iesg-secretary@ietf.org>                                       23.0\n",
      "\"Savolainen Teemu (Nokia-TECH/Tampere)\" <teemu.savolainen@nokia.com>     22.0\n",
      "\"Turner, Randy\" <Randy.Turner@landisgyr.com>                             20.0\n",
      "Thomas Watteyne <thomas.watteyne@inria.fr>                               18.0\n",
      "Brian E Carpenter <brian.e.carpenter@gmail.com>                          17.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# plotting the top-users for your convenience\n",
    "\n",
    "# set the number of top-users that you want to see\n",
    "max_users = 25\n",
    "\n",
    "if not users_from_file:\n",
    "    activity = Archive.get_activity(archives)\n",
    "    tot_activity = activity.sum(0).sort_values(ascending=False)\n",
    "    try:\n",
    "        print(tot_activity[:max_users])\n",
    "    except:\n",
    "        print(tot_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert in 'users' the list of users that you want to track\n",
    "\n",
    "\n",
    "users = [\n",
    "    \"Rene Struik <rstruik.ext@gmail.com>\",\n",
    "    '\"Ralph Droms (rdroms)\" <rdroms@cisco.com>',\n",
    "]\n",
    "\n",
    "user_wordcount = defaultdict(dict)\n",
    "\n",
    "for user in users:\n",
    "    messages = archives_data[archives_data[\"From\"] == user][\"Body\"]\n",
    "    user_wordcount[user] = count_words(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ralph Droms (rdroms)\" <rdroms@cisco.com>\n",
      "20   125\n",
      "ietf   96\n",
      "6lo   71\n",
      "org   66\n",
      "draft   53\n",
      "I   48\n",
      "document   40\n",
      "6man   39\n",
      "Ralph   37\n",
      "IPv6   35\n",
      "Rene Struik <rstruik.ext@gmail.com>\n",
      "ietf   95\n",
      "org   83\n",
      "I   79\n",
      "security   69\n",
      "draft   67\n",
      "6lo   60\n",
      "1   38\n",
      "The   35\n",
      "one   33\n",
      "bootstrapping   30\n"
     ]
    }
   ],
   "source": [
    "# insert the number of top words you want to export\n",
    "n_top_words = 10\n",
    "\n",
    "\n",
    "for user, wordcount in user_wordcount.items():\n",
    "    print(user)\n",
    "    for word, count in sorted(\n",
    "        iter(wordcount.items()), reverse=True, key=lambda k_v: (k_v[1], k_v[0])\n",
    "    )[:n_top_words]:\n",
    "        print(word + \"   \" + str(count[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
